{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from machine_learning import linear\n",
    "from machine_learning import preprocessing, validation, multiclass_classifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cufflinks as cf\n",
    "from scipy import stats\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\", \n",
    "    header=None, \n",
    "    names=[\n",
    "        \"id_number\", \n",
    "        \"clump_thickness\", \n",
    "        'uniformity_cell_size', \n",
    "        'uniformity_cell_shape', \n",
    "        \"marginal_adhesion\",\n",
    "        \"single_epithelial_cell_size\", \n",
    "        \"bare_nuclei\", \n",
    "        \"bland_chromatin\", \"normal_nucleoli\", \"mitosis\", \"class\"\n",
    "    ]\n",
    ").replace('?',np.NaN).astype('float', errors='ignore').dropna(how='any', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_X, breast_y = (\n",
    "    ss.fit_transform(breast_cancer.drop(['id_number', 'class'], axis=1).values),\n",
    "    breast_cancer['class'].astype('category').cat.codes.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(breast_y).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = validation.KFoldStratifiedCV(num_folds=5)\n",
    "accuracy_adaline = []\n",
    "accuracy_lr = []\n",
    "baseline = []\n",
    "for train, test in kfold.split(X=breast_X, y=breast_y):\n",
    "    sweet_adaline = linear.AdalineNetwork(\n",
    "        convergence_tolerance=.0001, \n",
    "        fit_intercept=True,\n",
    "        max_iter=10000, \n",
    "        learning_rate=.0001\n",
    "    )\n",
    "    \n",
    "    logistic_regression = linear.LogisticRegressionClassifier(\n",
    "        convergence_tolerance=.0001, \n",
    "        fit_intercept=True,\n",
    "        max_iter=10000, \n",
    "        learning_rate=.0001    \n",
    "    )\n",
    "    \n",
    "    baseline.append(np.mean(stats.mode(breast_y[train]).mode[0]  == breast_y[test]))\n",
    "\n",
    "    sweet_adaline.fit(breast_X[train], breast_y[train])\n",
    "    logistic_regression.fit(breast_X[train], breast_y[train])\n",
    "    accuracy_adaline.append(np.mean(sweet_adaline.predict(breast_X[test]) == breast_y[test]))\n",
    "    accuracy_lr.append(np.mean(logistic_regression.predict(breast_X[test]) == breast_y[test]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".linspace(-10, 10, .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.954506623411733, 0.9648121113814545, 0.6500783995674506]"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(np.mean, (accuracy_adaline, accuracy_lr, baseline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soybean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import pipe\n",
    "\n",
    "\n",
    "# Next, we repeat this process on the Soybean data\n",
    "soybean_data = pipe(\n",
    "    pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/soybean/soybean-small.data\",\n",
    "        header=None,\n",
    "        names=[\n",
    "            \"date\",\n",
    "            \"plant-stand\",\n",
    "            \"precip\",\n",
    "            \"temp\",\n",
    "            \"hail\",\n",
    "            \"crop-hist\",\n",
    "            \"area-damaged\",\n",
    "            \"severity\",\n",
    "            \"seed-tmt\",\n",
    "            \"germination\",\n",
    "            \"plant-growth\",\n",
    "            \"leaves\",\n",
    "            \"leafspots-halo\",\n",
    "            \"leafspots-marg\",\n",
    "            \"leafspot-size\",\n",
    "            \"leaf-shread\",\n",
    "            \"leaf-malf\",\n",
    "            \"leaf-mild\",\n",
    "            \"stem\",\n",
    "            \"lodging\",\n",
    "            \"stem-cankers\",\n",
    "            \"canker-lesion\",\n",
    "            \"fruiting-bodies\",\n",
    "            \"external decay\",\n",
    "            \"mycelium\",\n",
    "            \"int-discolor\",\n",
    "            \"sclerotia\",\n",
    "            \"fruit-pods\",\n",
    "            \"fruit spots\",\n",
    "            \"seed\",\n",
    "            \"mold-growth\",\n",
    "            \"seed-discolor\",\n",
    "            \"seed-size\",\n",
    "            \"shriveling\",\n",
    "            \"roots\",\n",
    "            \"instance_class\",\n",
    "        ],\n",
    "    )\n",
    "    .pipe(lambda df: df.loc(axis=1)[df.nunique() > 1])  # drop columns with no variance\n",
    "    .assign(instance_class=lambda df: df[\"instance_class\"].astype(\"category\").cat.codes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (\n",
    "    pd.get_dummies(\n",
    "        soybean_data.drop('instance_class', axis=1),\n",
    "        columns=soybean_data.drop('instance_class', axis=1).columns, \n",
    "        drop_first=True\n",
    "    ).values, \n",
    "    soybean_data['instance_class'].values\n",
    ")\n",
    "\n",
    "kfold = validation.KFoldStratifiedCV(num_folds=5)\n",
    "accuracy_adaline = []\n",
    "accuracy_lr = []\n",
    "baseline = []\n",
    "for train, test in kfold.split(X=X, y=y):\n",
    "    sweet_adaline = multiclass_classifier.MulticlassClassifier(\n",
    "        model_cls=lambda *args: linear.AdalineNetwork(\n",
    "            convergence_tolerance=.0001, \n",
    "            fit_intercept=True,\n",
    "            max_iter=1000, \n",
    "            learning_rate=.001\n",
    "        ), \n",
    "        classes=np.unique(y), \n",
    "        cls_kwargs={i: {} for i in np.unique(y)}\n",
    "    )\n",
    "    \n",
    "    \n",
    "    logistic_regression = linear.LogisticRegressionClassifier(\n",
    "        convergence_tolerance=.0001, \n",
    "        fit_intercept=True,\n",
    "        max_iter=1000, \n",
    "        learning_rate=.001\n",
    "    )\n",
    "    \n",
    "    sweet_adaline.fit(X[train], y[train])\n",
    "    \n",
    "    logistic_regression.fit(X[train], y[train])\n",
    "    \n",
    "    baseline.append(np.mean(stats.mode(y[train]).mode[0]  == y[test]))\n",
    "    accuracy_adaline.append(np.mean(sweet_adaline.predict(X[test]) == y[test]))\n",
    "    accuracy_lr.append(np.mean(logistic_regression.predict(X[test]) == y[test]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36, 1.0, 1.0]"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(np.mean, (baseline, accuracy_adaline, accuracy_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_data = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data\", \n",
    "    header=None,\n",
    "    names=[\n",
    "        \"id_number\",\n",
    "        \"refractive_index\",\n",
    "        \"sodium\",\n",
    "        \"magnesium\",\n",
    "        \"aluminum\",\n",
    "        \"silicon\",\n",
    "        \"potassium\",\n",
    "        \"calcium\",\n",
    "        \"barium\",\n",
    "        \"iron\",\n",
    "        \"class\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (\n",
    "    glass_data.drop(['id_number', 'class'], axis=1).values, \n",
    "    glass_data['class'].astype('category').cat.codes\n",
    ")\n",
    "\n",
    "kfold = validation.KFoldStratifiedCV(num_folds=5)\n",
    "accuracy_adaline = []\n",
    "accuracy_lr = []\n",
    "baseline = []\n",
    "for train, test in kfold.split(X=X, y=y):\n",
    "    sweet_adaline = multiclass_classifier.MulticlassClassifier(\n",
    "        model_cls=lambda *args: linear.AdalineNetwork(\n",
    "            convergence_tolerance=.0001, \n",
    "            fit_intercept=True,\n",
    "            max_iter=5000, \n",
    "            learning_rate=.005\n",
    "        ), \n",
    "        classes=np.unique(y), \n",
    "        cls_kwargs={i: {} for i in np.unique(y)}\n",
    "    )\n",
    "    \n",
    "    \n",
    "    logistic_regression = linear.LogisticRegressionClassifier(\n",
    "        convergence_tolerance=.0001, \n",
    "        fit_intercept=True,\n",
    "        max_iter=15000, \n",
    "        learning_rate=.005\n",
    "    )\n",
    "    \n",
    "    ms = preprocessing.MaxScaler()\n",
    "\n",
    "    ms.fit(X[train])\n",
    "\n",
    "    sweet_adaline.fit(ms.transform(X[train]), y[train])\n",
    "    \n",
    "    logistic_regression.fit(ms.transform(X[train]), y[train])\n",
    "    \n",
    "    baseline.append(np.mean(stats.mode(y[train]).mode[0] == y[test]))\n",
    "    accuracy_adaline.append(np.mean(sweet_adaline.predict(ms.transform(X[test])) == y[test]))\n",
    "    accuracy_lr.append(np.mean(logistic_regression.predict(ms.transform(X[test])) == y[test]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35548894258196584, 0.5050456391154066, 0.44838182489345285]"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(np.mean, (baseline, accuracy_adaline, accuracy_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/home/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6962616822429907"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_ones(X):\n",
    "    return np.concatenate(\n",
    "        [\n",
    "            np.ones((X.shape[0], 1)),\n",
    "            X\n",
    "        ], axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "lr = LogisticRegression(multi_class='ovr')\n",
    "lr.fit(glass_X, glass_y)\n",
    "np.mean(lr.predict(glass_X) == glass_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Adaline\n",
      "Fitting LR\n"
     ]
    }
   ],
   "source": [
    "iris_data = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", \n",
    "    header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    ")\n",
    "\n",
    "X, y = (\n",
    "    iris_data.drop(['class'], axis=1).values, \n",
    "    iris_data['class'].astype('category').cat.codes\n",
    ")\n",
    "\n",
    "kfold = validation.KFoldStratifiedCV(num_folds=5)\n",
    "accuracy_adaline = []\n",
    "accuracy_lr = []\n",
    "baseline = []\n",
    "for train, test in kfold.split(X=X, y=y):\n",
    "    sweet_adaline = multiclass_classifier.MulticlassClassifier(\n",
    "        model_cls=lambda *args: linear.AdalineNetwork(\n",
    "            convergence_tolerance=.0001, \n",
    "            fit_intercept=True,\n",
    "            max_iter=1000, \n",
    "            learning_rate=.005\n",
    "        ), \n",
    "        classes=np.unique(y), \n",
    "        cls_kwargs={i: {} for i in np.unique(y)}\n",
    "    )\n",
    "    \n",
    "    \n",
    "    logistic_regression = linear.LogisticRegressionClassifier(\n",
    "        convergence_tolerance=.0001, \n",
    "        fit_intercept=True,\n",
    "        max_iter=1000, \n",
    "        learning_rate=.005\n",
    "    )\n",
    "    \n",
    "    ms = preprocessing.MaxScaler()\n",
    "    \n",
    "    ms.fit(X[train])\n",
    "    print(\"Fitting Adaline\")\n",
    "    sweet_adaline.fit(ms.transform(X[train]), y[train])\n",
    "    \n",
    "    print(\"Fitting LR\")\n",
    "    logistic_regression.fit(ms.transform(X[train]), y[train])\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        np.hstack(\n",
    "            [\n",
    "                X[test], \n",
    "                y[test].values.reshape(-1, 1),\n",
    "                np.array(logistic_regression.predict(ms.transform(X[test]))).reshape(-1, 1),\n",
    "            ]\n",
    "        ), columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class', 'prediction']\n",
    "    ).to_csv(\"logistic_regression_iris_predictions.csv\",index=False)\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        np.hstack(\n",
    "            [\n",
    "                X[test], \n",
    "                y[test].values.reshape(-1, 1),\n",
    "                np.array(sweet_adaline.predict(ms.transform(X[test]))).reshape(-1, 1),\n",
    "            ]\n",
    "        ), columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class', 'prediction']\n",
    "    ).to_csv(\"adaline_iris_predictions.csv\", index=False)\n",
    "\n",
    "\n",
    "    \n",
    "    baseline.append(np.mean(stats.mode(y[train]).mode[0] == y[test]))\n",
    "    accuracy_adaline.append(np.mean(sweet_adaline.predict(ms.transform(X[test])) == y[test]))\n",
    "    accuracy_lr.append(np.mean(logistic_regression.predict(ms.transform(X[test])) == y[test]))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_votes_data = pipe(\n",
    "    pd.read_csv(\n",
    "        \"https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\",\n",
    "        header=None,\n",
    "        names=[\n",
    "            \"instance_class\",\n",
    "            \"handicapped-infants\",\n",
    "            \"water-project-cost-sharing\",\n",
    "            \"adoption-of-the-budget-resolution\",\n",
    "            \"physician-fee-freeze\",\n",
    "            \"el-salvador-aid\",\n",
    "            \"religious-groups-in-schools\",\n",
    "            \"anti-satellite-test-ban\",\n",
    "            \"aid-to-nicaraguan-contras\",\n",
    "            \"mx-missile\",\n",
    "            \"immigration\",\n",
    "            \"synfuels-corporation-cutback\",\n",
    "            \"education-spending\",\n",
    "            \"superfund-right-to-sue\",\n",
    "            \"crime\",\n",
    "            \"duty-free-exports\",\n",
    "            \"export-administration-act-south-africa\",\n",
    "        ],\n",
    "    )\n",
    "    .replace(\"?\", np.NaN)\n",
    "    .replace(\"y\", 1)\n",
    "    .replace(\"n\", 0), \n",
    "    lambda df: pd.get_dummies(df, columns=df.columns, drop_first=True, dummy_na=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (\n",
    "    house_votes_data.drop(['instance_class_republican', 'instance_class_nan'], axis=1).values, \n",
    "    house_votes_data['instance_class_republican'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = validation.KFoldStratifiedCV(num_folds=5)\n",
    "accuracy_adaline = []\n",
    "accuracy_lr = []\n",
    "baseline = []\n",
    "for train, test in kfold.split(X=X, y=y):\n",
    "    sweet_adaline = linear.AdalineNetwork(\n",
    "        convergence_tolerance=.0001, \n",
    "        fit_intercept=True,\n",
    "        max_iter=1000, \n",
    "        learning_rate=.0001\n",
    "    )\n",
    "    \n",
    "    logistic_regression = linear.LogisticRegressionClassifier(\n",
    "        convergence_tolerance=.0001, \n",
    "        fit_intercept=True,\n",
    "        max_iter=1000, \n",
    "        learning_rate=.0001    \n",
    "    )\n",
    "    \n",
    "    baseline.append(np.mean(stats.mode(y[train]).mode[0]  == y[test]))\n",
    "\n",
    "    sweet_adaline.fit(X[train], y[train])\n",
    "    logistic_regression.fit(X[train], y[train])\n",
    "    accuracy_adaline.append(np.mean(sweet_adaline.predict(X[test]) == y[test]))\n",
    "    accuracy_lr.append(np.mean(logistic_regression.predict(X[test]) == y[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6138052538212924, 0.953965274233919, 0.947147699934388]"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(np.mean, (baseline, accuracy_adaline, accuracy_lr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
